{"meta":{"title":"Charley's Hut","subtitle":"","description":"","author":"Charley Xiao","url":"http://charleyhut.github.io","root":"/"},"pages":[{"title":"About","date":"2023-01-26T06:42:20.175Z","updated":"2023-01-26T06:42:09.448Z","comments":true,"path":"about.html","permalink":"http://charleyhut.github.io/about.html","excerpt":"","text":"你好！欢迎来到我的小屋。在这个博客里我将会记录我的一些学习笔记，包括算法学习、语言学习等。欢迎交流！"},{"title":"","date":"2023-01-26T06:29:29.358Z","updated":"2023-01-26T06:29:24.663Z","comments":true,"path":"tags.html","permalink":"http://charleyhut.github.io/tags.html","excerpt":"","text":""},{"title":"","date":"2023-01-26T06:30:07.145Z","updated":"2023-01-26T06:30:00.175Z","comments":true,"path":"categories.html","permalink":"http://charleyhut.github.io/categories.html","excerpt":"","text":""}],"posts":[{"title":"【深度学习】用于Transformer的FLOATER位置编码","slug":"floater","date":"2023-05-15T14:12:00.224Z","updated":"2023-05-15T14:43:26.626Z","comments":true,"path":"2023/05/15/floater/","link":"","permalink":"http://charleyhut.github.io/2023/05/15/floater/","excerpt":"","text":"© Charleyxiao。未经授权，严禁转载。 由于博客排版有误，欢迎移至知乎阅读：https://zhuanlan.zhihu.com/p/629476200 0x00 来源论文Learning to Encode Position for Transformer with Continuous Dynamical Model 0x01 引言位置编码（Positional Encoding）是 Transformer 模型的预处理的一个重要部分。之所以引入位置编码，是为了解决自注意力机制（Self-attention）中没有办法区分输入向量之间距离的问题。具体来说，如果我们要处理 I love you. 这么一个句子，在没有位置编码的情况下，Transformer 架构会认为 I love 的距离和 I you 是一样的。总而言之，在自注意力机制里面，根本就没有位置的信息，但是实际上位置的信息有的时候是很重要的，因此位置编码机制应运而生。位置编码机制千奇百怪，而在上述论文中，它提出了一种叫作 FLOATER 的位置编码，这将是我们在这篇博客中讲解的重点。 0x02 位置编码让我们先来回顾一下位置编码具体是怎么操作的。假设在 Transformer 架构中，有一个输入向量 $a^i$，那么由它分别左乘三个矩阵 $W^q,W^k,W^v$ 得到 $q^i,k^i,v^i$，它们分别表示 $a^i$ 的 query、key 以及 value。那么 $a^i$ 对应的注意力值就是：$$\\alpha^i=[k^1,k^2,k^3,\\dots,k^L]^\\top q^i$$一般来说我们会对 $\\alpha^i$ 作 $\\rm softmax$ 操作，即 $\\alpha{^\\prime}^i=\\mathop{\\rm softmax}(\\alpha^i)$。这样我们就得到了自注意力。 正如前文所说，我们需要引入一个位置编码。而这个位置编码是和输入同大小的一串向量，比如对于 $a^i$ 就有一个对应的位置编码 $e^i$，这时我们就把 $a^i+e^i$ 作为输入向量。即：$$q^i=W^q(a^i+e^i)$$$$k^i=W^k(a^i+e^i)$$$$v^i=W^v(a^i+e^i)$$这看起来很简单，但实际上这个 $e^i$ 是需要由我们手动来设定一个生成规则的（虽然现在已经有人提出把它也作为可学习参数进入网络，但是至少最开始的时候是手工的）。其中比较著名的有 Sinusoidal、Position embedding 以及 RNN 生成，当然不要忘了这篇文章中提出的 FLOATER。它们分别长这样： 其中，越深色代表越接近-1，越浅色代表越接近1。 这篇论文同时也对比了一下这几种方法： 可以看到，它所提出的 FLOATER 还是非常优秀的。 0x03 FLOATER接下来进入正题，介绍一下FLOATER。 FLOATER 全称 FLOw-bAsed TransformER（事实上在这篇论文里面你可以看到 FLOWER 和 FLOATER 两种表述，它们是一种东西，只是取了不同的首字母而已，不是很清楚为什么论文作者们没有统一一个名称），它的主要思想是将位置编码建模为连续动态系统（Continuous Dynamical System），因此只需要学习系统动态而不是独立地学习每个位置的嵌入向量 $e^i$。 所谓连续动态系统，它描述了在连续时间内，系统的状态如何随时间变化而变化。这种系统通常用微分方程来描述，其中系统的状态在任意时刻都由状态变量和它们的导数（即状态变量随时间的变化率）来表示。 为了使网络能够通过反向传播进行训练，这篇论文采用了神经常微分方程（Neural ODE），即自由形式流模型（Free-form Flow Model）。 0x03-1 动态系统位置编码这里我们统一将符号改为和论文中的一致。位置编码是一个向量序列 ${p^i\\in \\mathbb{R}^d:i=1,\\dots,L}$，输入向量 ${x^i\\in\\mathbb{R}^d:i=1,\\dots,L}$。 既然采用了动态系统的架构，那么我们认为有一个潜在力（latent force），记为 $h^i$，是它把将 $p^i$ 转移到了 $p^{i+1}$。 那么假设函数 $p(t)$ 是 ${p^i}$ 的连续光滑版本，我们的动态系统应该满足：$$p(t)=p(s)+\\int_s^th(\\tau,p(\\tau);\\theta_h){\\rm d}\\tau,0\\le s\\le t&lt;\\infty$$其中，$h(\\tau,p(\\tau);\\theta_h)$ 代表参数 $\\theta_h$ 和前一时刻状态 $(\\tau,p(\\tau))$ 构成的神经网络。 既然 ${p^i}$ 是离散的而 $p(\\cdot)$ 是连续的，我们可以取 ${t^i=i\\cdot\\Delta t}:p^i=p(t^i)$，其中这个 $\\Delta$ 是一个超参数，论文里设置的是 $\\Delta=0.1$。 不难看出，上面的由 $p(s)$ 到 $p(t)$ 的转移方程实际上可以表达成一个常微分方程问题：$$\\dfrac{\\mathrm{d}p(t)}{\\mathrm{d}t}=h(t,p(t);\\theta_h)$$为了训练网络，在反向传播过程，我们需要求解损失函数 $L(p^0,\\dots,p^L)$ 关于 $\\theta_h$ 的梯度。我们有：$$\\dfrac{\\mathrm{d}L}{\\mathrm{d}\\theta_h}=-\\int_t^s a(\\tau)^\\top\\dfrac{\\partial h(\\tau,p_\\tau;\\theta_h)}{\\partial\\theta_h}\\mathrm{d}\\tau$$其中 $a(\\tau)$ 是常微分方程的伴随状态，可以由另一个常微分方程计算：$$\\dfrac{\\mathrm{d}a(\\tau)}{\\mathrm{d}\\tau}=-a(\\tau)^\\top\\dfrac{\\partial h(\\tau,p_\\tau;\\theta_h)}{\\partial p_\\tau}$$在后面我们会讲到如何设置常微分方程的自动求解器。 0x03-2 块间参数共享我们知道，在 seq2seq Transformer 的架构中一共有6个块，BERT 有12或24个块，我们可以尝试在每一个块都进行位置编码来优化网络的性能。但是同时拥有 $N$ 个不同的动态系统 $h^{n}(\\cdot;\\theta_h^n)$ 会引入很多参数，这样的话训练开销会很大。因此，我们令：$$\\theta_h^1=\\theta_h^2=\\dots=\\theta_h^N$$ 0x03-3 对原始 Transformer 的兼容性实际上，FLOATER 和原始的 Transformer 模型是兼容的。我们考虑正弦式编码（sinusoidal encoding）：$$\\tilde{q}^i=W^q(x^i+\\tilde{p}^i)+b^q$$这个公式的意思是，一个输入向量的 query 值是 $\\tilde{q}^i$ 是由模型参数 $W^q,b^q$ 以及它本身 $x^i$ 和位置编码 $\\tilde{p}^i$ 计算而来的。$\\tilde{k}^i,\\tilde{v}^i$ 以此类推，不赘述。 假如引入的是 FLOATER 模型，那么就有：$$q^i=W^q(x^i+p^i)+b^q$$$$=W^q(x^i+\\tilde{p}^i)+b^q+W^q(p^i-\\tilde{p}^i)$$$$=\\tilde{q}^i+b^{q,i}$$可以看到，从正弦式编码到 FLOATER 本质上就是把原来的偏置 $b^q$ 改成了一个考虑位置 $i$ 的新偏置 $b^{q,i}$。因此，我们就有了这样的动态系统：$$b^q(t)=b^q(0)+\\int_0^th(\\tau,b^q(\\tau);\\theta_h)\\mathrm{d}\\tau$$在此基础上，我们令 $b^{q,i}=b^q(i\\cdot\\Delta t)$。而当 $h(\\cdot)=0,b^q(0)=0$ 时，有 $q^i=\\tilde{q}^i$，即 FLOATER 退化为了正弦式编码。 因此，利用这种兼容性，我们可以直接用预训练的 Transformer 模型初始化 FLOATER 模型，然后在下游任务进行微调。而对于类似 BERT 或 Transformer-XL 之类的模型，我们已经为下游任务提供了 checkpoint。为了对比 FLOATER 模型和其他模型的表现，论文中逐层复制了注意力和 FFN 层的权重，并随机初始化了 $h(\\tau,p(\\tau);\\theta_h)$。 0x04 实现及实验结果论文把 FLOATER 放在了一些 NLP 任务中进行测试并与其他模型进行了比较。 0x04-1 设置常微分方程自动求解器论文用的常微分方程求解器是经过修改的 torchdiffeq 库，可以在此链接下载。 神经机器翻译任务上，采用步长 $\\dfrac{\\Delta}{5.0}$（前面设置了 $\\Delta=0.1$）的 Runge-Kutta 法（即通过计算在每个时间步长之间各个中间点的解斜率的加权平均数来近似计算ODE的解），在 GLUE 和 RACE 上测试。 0x04-2 神经机器翻译任务论文运行了由 fairseq 提供的预处理脚本成功复现了 Transformer 论文 Attention is all you need 中的所有结果，然后按照下面的步骤获得了这篇论文的结果： 对原始 Transformer 模型进行30个 epoch 的训练； 随机初始化 FLOATER 模型； 从验证集里表现最佳的 checkpoint 初始化 FLOATER 模型，同时给动态模型里的权重 $\\theta_h$ 赋一个比较小的值； 将峰值学习率减半； 使用预处理好的 FLOATER checkpoint，在相同的数据集上进行10个 epoch 的英德翻译训练和1个epoch 的英法翻译训练； 对最后5个 checkpoint 取平均，并在测试集上计算 BLEU 分数。 以下是实验结果： 0x04-3 语言理解任务对于 GLUE/SQuAD/RACE 基准测试，论文中的实验都是基于 RoBERTa 进行的，包括 base 和 large 两种配置。由于资源限制，使用的是预训练的 RoBERTa 来初始化 FLOATER 模型，类似于神经机器翻译任务。但是由于 GLUE/SQuAD/RACE 数据集过小，无法从头开始训练，因此动态系统动态函数 $h(\\tau,p(\\tau);\\theta_h)$ 的权重 $\\theta_h$ 是在 WikiText103 数据上使用 Masked Language Modeling Loss 进行预训练的，而且只训练 $\\theta_h$。所谓 Masked Language Modeling Loss，指的是输入的文本序列中的一些词语被随机遮蔽，模型需要预测这些遮蔽词语的正确词汇。这可以让模型学会从上下文中推断出遮蔽掉的词语，从而提高模型对于语言的理解和生成能力。论文发现单独训练 $\\theta_h$ 时，只需要几个小时（配置是2个 Titan V100）和一个训练周期就可以达到收敛。 GLUE 基准：8个数据集和不同的超参数设定。论文使用的是和 RoBERTa 中一样的超参数。 SQuAD 基准（来源1 和 来源2）：论文自己写了微调代码，同样使用的是 RoBERTa 里面的超参数。 RACE 基准：有最长的上下文和序列长度。使用 RoBERTa 里的超参数。冻结权重 $\\theta_h$，并且只微调 RoBERTa 的权重。 以下是实验结果： 0x05 讨论与分析0x05-1 泛化能力论文作者们注意到在 WMT14 英德数据集上有98.6%的训练句少于80个 tokens，所以他们做了一个新的数据集，En-De short to long，简称 S2L，即把小于80个 tokens 的句子作为训练集，其余的作为测试集，而又进一步将测试集根据 tokens 数量分为4个部分：$[80,100),[100,120),[120,140),[140,+\\infty)$，计算出来的 BLEU 分数如下： 可以看出，FLOATER 的泛化能力非常优秀，即便是训练集只提供短句子，也能够适用于长句子。 0x05-2 与 RNN 的比较众所周知，RNN 也可以用于序列模型，而且和 FLOATER 一样，第 $i$ 步也是依赖于第 $(i-1)$ 步的。论文就将 RNN 与 FLOATER 的性能进行了对比。$$p^{i+1}=\\mathrm{RNN}(z^i,p^i)$$其中 $p^i$ 是之前提到的位置编码，$z^i$ 是 $i$ 处 RNN 的输入。实验结果如下： 0x05-3 训练与测试效率由于利用流模型求解神经常微分方程一次需要大概100次前向和反向传播，再加上常微分方程求解器无法利用 GPU 并行运算的优势，FLOATER 模型的开销是非常大的。论文提出了以下几种方法来改进： 利用已经训练好的模型来初始化； 用较小的数值初始化 FLOATER； 因为 $h(\\cdot)$ 训练起来比较容易和稳定，可以将它与网络的其他部分分离出来； 对于 RoBERTa 模型，直接下载预训练的模型，插入 FLOATER 编码层，然后重新训练编码层；而在 GLUE 上微调时，直接冻结编码层使它不变。 利用上述方法，FLOATER 只花了比 Transformer 多20-30%的时间来训练。 0x06 总结与展望这篇论文将 Neural ODE 和 Transformer 结合起来提出了 FLOATER 模型，并取得了较好的效果。但是自然语言的高度离散化让连续性假设可能不再实用，而且 Neural ODE 仍处于发展阶段，没有得到广泛的应用。而且 TENER 指出本文（以及其他传统模型）将位置编码和输入向量相加的方式会导致位置编码在后续变换中消失。 0x07 参考文献[1] Learning to Encode Position for Transformer with Continuous Dynamical Model: https://arxiv.org/abs/2003.09229 [2] TENER: Adapting Transformer Encoder for Named Entity Recognition: https://arxiv.org/abs/1911.04474","categories":[],"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://charleyhut.github.io/tags/DeepLearning/"}]},{"title":"希伯来语动词变位小结","slug":"verb_inflection","date":"2023-01-27T09:12:53.727Z","updated":"2023-01-27T09:22:53.032Z","comments":true,"path":"2023/01/27/verb_inflection/","link":"","permalink":"http://charleyhut.github.io/2023/01/27/verb_inflection/","excerpt":"","text":"希伯来语中，每一个动词都属于七大类 $binyan(im)$ 中的一种，且都拥有一个词根。在这篇笔记中，我将会一一列出它们在动词变位方面拥有一些共同点。这只是一个归纳小结，实际上还有很多需要注意的地方，对于每一类动词都不同；但我这里仅仅只是列出共同点，或者可以看作是一个概论。参考资料：Lewis Glinert - Modern Hebrew: An Essential Grammar 过去时动词的过去时由词根加上一个后缀形成，实际上这些后缀和对应的人称代词有着一些关联，可以联系着记忆。如下（对应的有联系的人称代词在括号中）： 单数 复数 第一人称 תּי (אני) נוּ (אנחנו) 第二人称阳性 תָּ (אתה) תֶּם (אתם) 第二人称阴性 תְּ (את) תֶּן (אתן) 第三人称阳性 无后缀 וּ 第三人称阴性 ה ָ וּ 其中，第一人称和第二人称的后缀是不带重音的，而第三人称的后缀带不带重音取决于动词的种类。 第一人称和第二人称经常不带代词使用。 在用法方面，希伯来语的过去时基本上覆盖了英语中的四种过去时态。 现在时动词的现在时也是由词根加上一个后缀形成。 单数 复数 阳性 无后缀 יִם 阴性 ה ָ 或者 ת ֶ וֹת 不难看出这些变位和名词的阴阳单复的特征有着一些共同点。 在用法方面，希伯来语的现在时基本上覆盖了英语中的一般现在时和现在进行时。 将来时动词的将来时由词根加上前缀（和后缀）形成。前缀在这里没有注音，因为实际上不同的动词类型中这些前缀带的元音也是不同的。这里我也附带上了和前后缀有联系的人称代词来辅助记忆。 单数 复数 第一人称 א… (אני) נ… (אנחנו) 第二人称阳性 תּ… (אתה) תּ…וּ (אתם) 第二人称阴性 תּ…י (את) תּ…וּ (אתן) 第三人称阳性 …י י…וּ 第三人称阴性 …תּ י…וּ 希伯来语的将来时有两种用法： 等同于英语中的将来时； 其第二人称可以用于祈使。 需要注意的是，在否定情况下，用法1和用法2所使用的否定词不一样。 你不会起来的。 别起来。 לא תָּקוּם אַל תָּקוּם 除此之外，希伯来语还有动词的命令式来表达肯定形式的用法2。 口语中，用法1的第一人称和第二人称常带代词；而在更正式的语体中，一般不带代词。 命令式命令式只有三种变位，通过加后缀实现，实质上就是将来时第二人称的后缀。 阳性单数 无后缀 阴性单数 י ִ 复数 וּ 这里的阴阳性指的是命令的对象的阴阳性。 除了后缀，命令式的形式还和动词本身所属的 $binyan$ 密切相关。但总体来说，命令式要么长得像将来时要么长得像不定式。 希伯来语的命令式只能用于肯定形式且比将来时更加正式。对于否定的情况，是使用对应的将来时形式。 不定式不定式不随阴阳单复屈折。所有不定式都带有前缀 ל，而不定式的主体则取决于 $binyan$ 和词根。 不定式的用法和英语中的相差无几，比如 it’s hard to …, I want to… 等。还有一个用法是一种“上级对下级”式的命令或指示，尤其是对孩子、军队或者一群人。比如： לָרוּץ, יְלָדִים 孩子们，跑！ 词根与词基大多数希伯来语词都围绕一个词根(root)和一个词基(base)来构成。词基就是一个词去除所有有意义的前后缀之后的形式。而词根只是一串辅音，本身没有读音。举个例子： 词根 词基 带前（后）缀的词 ק־ם מָקוֹם 地方 מְקוֹםִי 我的地方；מְקוֹםוֹת 地方（复数） 以上就是对希伯来语动词变位的一个小结。下一篇笔记我可能会介绍一下七种 $binyan(im)$。","categories":[],"tags":[{"name":"Language","slug":"Language","permalink":"http://charleyhut.github.io/tags/Language/"}]},{"title":"Daddish","slug":"daddish","date":"2023-01-26T06:41:08.310Z","updated":"2023-01-26T06:42:10.459Z","comments":true,"path":"2023/01/26/daddish/","link":"","permalink":"http://charleyhut.github.io/2023/01/26/daddish/","excerpt":"","text":"DaddishLast Edited: 2022/05/04 &amp; 2022/10/04(Not Updated) WelcomeWelcome to the tutorial of Daddish, a constructed language created by me. From the following tutorial, you will acquire a basic knowledge of the grammar of Daddish and learn to speak it. IntroductionDaddish is the official language of Dad Republic (Daddish: Konharmonёšost Dadad), Earth 0xffffffff. Daddish was invented by a linguist, Vasily Xiao (Daddish: Šjao Vasinёo), and has been promoted nationwide in Dad Republic since its birth. Resources Memorizing Daddish Words Daddish Culture, History, Art, Literature Etc FeaturesWhy should you learn Daddish? Well, for fun, of course! Apart from that, Daddish has some amazing features, including: 9 Grammar Cases; Simple Construction of Words (you can literally construct any word based on its meaning); Restrictive/Non-restrictive Adjectives; Vowel Harmony; Etc… So, let’s get started! Overview Alphabet Verb Construction Person&amp;Number Time&amp;Type Voice Noun Construction Article Case Adjective&amp;Adverb Basic Structure Compound Structure Preposition Not-Attributive-Clause Active Verb-adjective Passive Verb-adjective Not-Nominal-Clause Not-Adverbial-Clause Text Dictionary AlphabetThe alphabet of Daddish is pretty easy, which includes all the letters of the English alphabet except q, w, x and y. And there are also š and č, which respectively represent the sounds sh (as in shove) and ch (as in chance). The letter ё represents the sound [jo], same as that in Russian. Letters (Capital) Letters (Lower) Pronunciation A a /a/ B b /b/ C c /ts/ D d /d/ E e /e/ F f /f/ G g /g/ H h guttural /h/ I i /i/ J j /j/ K k /k/ L l /l/ M m /m/ N n /n/ O o /o/ P p /p/ R r /r/ S s /s/ T t /t/ U u /u/ V v /v/ Z z /z/ Š š /ʃ/ Č č /tʃ/ Ё ё /jo/ VerbConstructionThe verbs in Daddish are very constructed. The original form of a verb always ends with č. If we take that č away, we call the rest the root of the verb. Basically a conjugated verb looks like this:$$\\rm (Negative\\ Prefix)+(Directional\\ Prefix)+(Aspect\\ Prefix)+Root+Person+Number+Time&amp;Type+(Voice)$$Besides, note that, for the suffixes to attach, it follows the rule of vowel harmony. The vowels in suffixes are always consistent with the last vowel of the root (with a few exceptions). Additionally, when attaching a suffix, you need to pay attention to the end of the word. Let’s say you are attaching the suffix f to the morpheme lek. lek ends with a consonant k, so it should be lekef after conjugation. Similarly, if the ending is a vowel, f becomes fa/fe/fi/fo/fu instead of af/ef/if/of/uf. Person&amp;NumberIn Daddish, the concept of “plural” doesn’t work. Daddish has three types of numbers: Singular, Type II and Type III. Singular, also Type I, is used to represent things in total of 1. Type II is used for 2,3,4 and numbers that end with 2,3,4. Type III is for those that cannot fit in Type I or Type II. Here comes the conjugation table of $\\rm Person$: First Person Second Person Third Person f r (Inclusive) / ss (Exclusive) t And $\\rm Number$: Singular Type II Type III (None) v k Thankfully this works for nouns too! Example: (a) machine (2,3,4…) machines (5…) machines maščin maščiniv maščinik Time&amp;TypeTense consists of aspect and time. There are three times in Daddish: Past, Present, and Future. There are also three types: declarative, imperative, and reportative. Reportative is used when the speaker is reporting what was told. Past Present Future Declarative m š g Imperative šd šd šd Reportative lm tš tg Now that you have learned all the basic verb conjugation, we can make some sentences: Seve leporokotovolm sjadvimaščinih. They(Type II) are said to have got a car. Se (He)+ ve= Seve (They,Type II) le (come)+ po (perfective prefix)+ rok (hand)+ č= leporokč (to get) leporok (root of to get)+ ot (third person)+ ov (Type II)+ olm (past reportative)= leporokotovolm (are said to have got) sjad (self)+ vi (move)+ maščin (machine)+ ih (accusative)= sjadvimaščinih(car, accusative) VoiceFor passive voice, a -sja/sje/sji/sjo/sju is attached to the conjugated verb. The vowel depends on the root. For active voice, this is not needed. NounConstructionThe nouns in Daddish are usually constructed in such way:$$\\rm Prefix+Root+Suffix\\ with\\ a\\ Meaning+Number+Case+Article$$We have already discussed the $\\rm Number$ in the previous section. ArticleIn Daddish, there is only definite article. But the definite article can sometimes be omitted, and sometimes can even express the meaning of “that/this/those/these”. The definite article looks like this:$$\\rm …-ta/te/ti/to/tu$$The vowel, again, should be in line with the root’s. Articles don’t do case conjugation. CaseThere are nine grammar cases in Daddish: Nominative (None) Genitive d Dative z Accusative h Instrumental $\\rm [vowel]+hm$ or $\\rm [consonant]+[vowel]+hm$ Locative p Topicative c Ablative b Vocative s NominativeThe nominative case marks the subject of a verb. When the verb is active, the nominative is the person or thing doing the action; when the verb is passive, the nominative is the person or thing receiving the action. Malcik-ti glazatam boloh-to. The boy saw the ball. Bol-to glazatamsja malcikihm-ti. The ball was seen by the boy. GenitiveThe genitive case has the basic usage of showing possession, along with other derived usage. possession thinkik Dzaneted Janet’s drinks composition kup manakad a group of men reference kapital konharmonёšostod-to capital of the republic DativeThe dative case is used to mark the indirect object. Se darokotom malcikiz giftih. He gave a boy a gift. It can be also used to express the meaning of “to somebody”. Seze ce delo tovnёo. To him, it is a good deed. AccusativeThe accusative case is used to mark a direct object, or after a few prepositions. Tehe amofošo. I love you. Musufug fu-dvaha sekunduvud. I will talk for two seconds. InstrumentalThe instrumental case shows the meaning of “by means of” or “by use of”, or, in passive voice, shows the implementer of an action. Pišifiš penehm. I’m writing with a pen. Bol-to glazatamsja malcikihm-ti. The ball was seen by the boy. LocativeThe locative case shows the location or time. Moskvapa ce komennёe. In Moscow, this is common. TopicativeThe topicative case is a unique case in Daddish. It marks the topic, usually something the speaker is talking about. Šotoc ke knosotoš-c! About death, who knows! It can also be used to change the structure of the sentence for whatever reason. Ekzamac Gokanёac, se častandataš cepe. He is taking part in the National Exam. AblativeThe ablative case expresses the meaning of “out of” or “from”. Ce hobotomsjo manab. This was stolen from a man. VocativeThe vocative case is a grammatical case which is used for a noun that identifies a person (animal, object, etc.) being addressed. Dzjonos, verešd! John, come! Adjective&amp;AdverbBasic StructureIn Daddish, there are two types of adjectives: restrictive and non-restrictive. The original form of a restrictive adjective ends with tornё, while a non-restrictive one just ends with nё. And adjectives also conjugates:$$\\rm …nё+[the\\ last\\ vowel\\ in\\ the\\ root\\ of\\ the\\ modified\\ noun]+[corresponding\\ case\\ ending,\\ just\\ like\\ a\\ noun]$$ Djakak kelez titekez tovnёeze! Thanks to all great teachers. (non-restrictive, indicating all teachers are great, and thanking all the teachers) Djakak kelez titekez tovtornёeze! Thanks to all teachers who are great! (restrictive, indicating you are only thanking good teachers, not bad ones) Adverbs are often derived from adjectives, by changing the nё into no. Adverbs never conjugate. Compound StructureNon-restrictive: Prinscipl Vzimvidostod uroktoknёi Einsteinehm ku šokotomnёi fizikmestostod Principle of Relativity, which was put forward by Einstein and shocked the field of physics The adherent adjuncts are connected with ku, which means and. al can be also used, which means or. Restrictive: rubblat-ta s-vahtahm Viniidi kutor ustoktornёa fu-markostoh that red pen with Winnie the Bear on it which is used for marking The adherent adjuncts are connected with kutor instead of ku, and altor instead of al. Preposition Preposition Meaning Case Required fu for Acc. s with Ins. oz against Gen. vkruh around Gen. bifuh before(time) Acc. aft after(time) Acc. ans inside Loc. cent at the center of Gen. em among Gen. fprid in front of Gen. znafp before(space) Gen. čerz through, over Acc. undeh under Ins. dov lasting for(time) Acc. vza while, when Gen. til until Gen. ot because of Gen. lefi in order to, for Gen. sin within Acc. oht without Gen. vasi thanks to Acc. Not-Attributive-ClauseBreaking news: there is no such thing as an “attributive clause” in Daddish! The meaning of the clause is expressed by compound structure, which consists of special adjectives derived from verbs and other stuffs. Active Verb-adjectiveAn active verb-adjective is used to modify a noun that is the implementer of an action. An active verb-adjective is constructed on the basis of a verb.$$\\rm Active\\ Verb-adjective=[conjugated\\ verb]+(tor)+nё$$For example: šokč (to shock)&gt; šokotom (shock, third person, past)&gt; šokotomnё (which shocked) Passive Verb-adjectiveA passive verb-adjective is used to modify a noun that is the patient of an action. A passive verb-adjective is also constructed on the basis of a verb, but has two different structures:$$\\rm [conjugated\\ verb]+(tor)+nё$$or$$\\rm [verb\\ without\\ suffix\\ or\\ č]+tok+nё$$The first one gives the exact information of the action, while the second doesn’t emphasize the time or person. And remember, the implementer of the action should be in instrumental case. For example: urokč (to put forward)&gt; uroktoknё (put forward, passive)&gt; uroktoknё Einsteinehm (put forward by Einstein) urokč (to put forward)&gt; urokotomsjonё (an object was put forward)&gt; urokotomsjonё Einsteinehm (an object put forward by Einstein) Not-Nominal-ClauseAnother breaking news: there is no such thing as a “nominal clause” in Daddish! The corresponding meaning is expressed by some structures. ObjectWhen the noun acts as an object in the “clause”, for example:$$\\rm I\\ know\\ \\underline{what}\\ she\\ has\\ said.$$Then the structure in Daddish looks like this:$$\\rm I\\ know,\\ she\\ [magic\\ word]\\ has\\ said.$$And the magic word is suhu. So the actual sentence looks like this:$$\\rm Knosofoš,\\ sa\\ suhu\\ pogavatam.$$Basically, suhu is put before the action in the “clause”, and altogether the structure becomes the object of knosofoš. But this is just basic. Actually, the true magic word is su, and suhu is the accusative case of it. The real rule is: If two parts share the same case, like the example above (both accusative), then put the su right before the action in the “clause” and change it into the correct case. If two parts don’t share the same case, then we need two su. They are put together like su-su, also right before the action in the “clause”. The first one conjugates according the main clause, and the second the subordinate clause. Knosofoš, sa suhu-supu zivitim. I know where she lived. And if there is a preposition: Memefeš, jeve sekundukuh bifuh suhu-oz-sudu photicifivim. I remember against whom we fought seconds ago. Not-Adverbial-ClauseMaterialsLesson 1: Meeting at a CafeA. TextKlor ku Ann musutuvuš čerz telefonoho. Klor: Dictionary Daddish English Daddish English je I drink te you (sing.) eat se he bite sa she suck ce this spit če that vomit cegda here blow čegda there breathe ket who laugh cet what see šat when hear gda where know (a fact) ko how think zna not smell kel all fear toma many sleep soma some live isma few kill otha other die ii one fight ai two hunt ci three hit fo four cut no five split ši six stab cem seven scratch osm eight dig dev nine swim des ten fly iičdes eleven walk aičdes twelve come cičdes thirteen lie fočdes fourteen sit nočdes fifteen stand šičdes sixteen turn cemčdes seventeen fall osmčdes eighteen hold devčdes nineteen squeeze aidesev twenty rub bignё big wash dninё long wipe zkonё wide pull honё thick push vecnё heavy throw šotnё short tie mlenknё small sew nahonё narrow count tinnё thin say uman woman sing man man (male) play human man (human being) float kit kid flow muman wife freeze maman husband swell uth mother sun path father moon zvunёšost animal star dag fish water ptic bird rain haund hound river laus louse lake zmja snake sea čoz worm salt riu tree stone riunost forest sand stik stick dust uvod fruit earth hum seed cloud liv leaf fog enhum root sky uriu bark (from a tree) wind cvet flower snow kas grass ice hop rope smoke uhuman skin fire nezvun meat ashes blood burn bone road fat (n.) mountain egg red horn green tail yellow feather white hair black head golden ear gold eye silver nose iron mouth steel tooth night tongue day fingernail afternoon foot noon leg evening knee year hand month wing week belly hour guts minute neck second back warm breast cold heart full liver new old pen good eraser bad desk rotten table dirty chair straight stool round toilet sharp class dull classroom smooth grade (1,2,3…) wet score dry goal correct dream near achievement far factory right airport left station name hall if cafeteria pencil house","categories":[],"tags":[{"name":"Gibberish","slug":"Gibberish","permalink":"http://charleyhut.github.io/tags/Gibberish/"}]}],"categories":[],"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://charleyhut.github.io/tags/DeepLearning/"},{"name":"Language","slug":"Language","permalink":"http://charleyhut.github.io/tags/Language/"},{"name":"Gibberish","slug":"Gibberish","permalink":"http://charleyhut.github.io/tags/Gibberish/"}]}